{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LDA","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"xh4H-m_lzluE","executionInfo":{"status":"ok","timestamp":1618342965280,"user_tz":-120,"elapsed":515,"user":{"displayName":"Camila Matoba","photoUrl":"","userId":"03259805399502182986"}}},"source":["import os\n","import tarfile\n","from six.moves import urllib\n","\n","#Variables\n","file_path = os.path.join(\".\")\n","file_name = \"OlsenVeg.csv\"\n","file_url =\"https://raw.githubusercontent.com/octokami/PredictiveBiomeModelling/master/OlsenVeg.csv\"\n","\n","#Import\n","def fetch_file_data(file_url, file_path):\n","  os.makedirs(file_path, exist_ok=True)\n","  csv_path = os.path.join(file_path, file_name)\n","  urllib.request.urlretrieve(file_url, csv_path)\n","fetch_file_data(file_url, file_path)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEtVkZJjz7Tn","executionInfo":{"status":"ok","timestamp":1618342965526,"user_tz":-120,"elapsed":740,"user":{"displayName":"Camila Matoba","photoUrl":"","userId":"03259805399502182986"}}},"source":["    import pandas as pd\n","    from sklearn.model_selection import train_test_split\n","    from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n","\n","    #Minimum number of sites for a biome \n","    min_sites=10\n","    #Removing taxas where the sum for the whole database is less than the threshold\n","    threshold=3\n","    #Test size for the split\n","    test_size=0.1\n","    # Set random seed for repeatability\n","    seed=42\n","    #For the StratifiedKFold\n","    n_folds = 10\n","\n","\n","    # Load the csv using pandas\n","    df = pd.read_csv('OlsenVeg.csv')\n","\n","    # Filter rows for biomes that occur in less than 10 sites\n","    df = df.groupby(\"BIO_N\").filter(lambda x: len(x) >= min_sites)\n","\n","    ##Categoricals can only take on only a limited, and usually fixed, number of possible values (categories). In contrast to statistical categorical variables, a Categorical might have an order, but numerical operations (additions, divisions, â€¦) are not possible.\n","    cat = pd.Categorical(df.BIO_N)\n","    # Convert category names to numbers\n","    y = cat.codes\n","    # Store names of the categories (i.e. biomes)\n","    labels = cat.categories\n","    \n","    # Remove non-pollen columns; all rows, starting at 9th column onwards\n","    pollen_only = df.iloc[:, 9:] \n","\n","    # Convert data to a matrix\n","    ##pandas.DataFrame.values: Only the values in the DataFrame will be returned, the axes labels will be removed.\n","    pollen_matrix = pollen_only.values\n","\n","    # Rename input data (pollen) to 'x', output data (biomes) to 'y'\n","    x = pollen_matrix.copy()\n","\n","    #Removing taxas\n","    x = x[:,(x > threshold).sum(axis=0) != 0]\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2StnwIu0iUX","executionInfo":{"status":"ok","timestamp":1618342965528,"user_tz":-120,"elapsed":736,"user":{"displayName":"Camila Matoba","photoUrl":"","userId":"03259805399502182986"}}},"source":["# Scale values so between [0,1]s\n","#x /= 100\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler(copy=False)\n","x = scaler.fit_transform(x)\n","\n","# Scale only columns that have values greater than 1\n","#to_scale = [col for col in df.columns if df[col].max() > 1]\n","#mms = MinMaxScaler()\n","#scaled = mms.fit_transform(merged[to_scale])\n","#scaled = pd.DataFrame(scaled, columns=to_scale)\n","\n","# Replace original columns with scaled ones\n","#for col in scaled:\n","#    merged[col] = scaled[col]\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"S7MzRwyA0miK","executionInfo":{"status":"ok","timestamp":1618342965853,"user_tz":-120,"elapsed":1056,"user":{"displayName":"Camila Matoba","photoUrl":"","userId":"03259805399502182986"}}},"source":["#from imblearn.over_sampling import SMOTE\n","\n","# creating a dataset with SMOTE application \n","#smt = SMOTE(random_state=seed)\n","\n","#x, y = smt.fit_resample(x, y)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"42swioza0uWV","executionInfo":{"status":"ok","timestamp":1618342965854,"user_tz":-120,"elapsed":1051,"user":{"displayName":"Camila Matoba","photoUrl":"","userId":"03259805399502182986"}}},"source":["# Split into train/test sets. Training set = 90%\n","##stratify parameter will preserve the proportion of target as in original dataset, in the train and test datasets as well. Often, we want to preserve the dataset proportions for better prediction and reproduceability of results\n","x, x_test, y, y_test = train_test_split(x, y, test_size=test_size, random_state=seed, stratify=y)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zf6T8M-S00XO","executionInfo":{"status":"ok","timestamp":1618342965855,"user_tz":-120,"elapsed":1046,"user":{"displayName":"Camila Matoba","photoUrl":"","userId":"03259805399502182986"}}},"source":["from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n","\n","pipe = LinearDiscriminantAnalysis(n_components = 3, solver = 'svd')\n","pipe.fit(x, y)\n","#lin_reg.intercept_, lin_reg.coef_\n","##predict_proba: Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_\n","y_proba = pipe.predict_proba(x_test)\n","##numpy.argmax(a, axis=None, out=None): Returns the indices of the maximum values along an axis. Axis= is the highest for each column.\n","y_pred = y_proba.argmax(axis=1)\n","\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1YtZ-Mo1YYE","executionInfo":{"status":"ok","timestamp":1618342965856,"user_tz":-120,"elapsed":1042,"user":{"displayName":"Camila Matoba","photoUrl":"","userId":"03259805399502182986"}},"outputId":"1476eabb-8c3c-4156-8b0a-649321c498bd"},"source":["    from sklearn import metrics\n","    from functools import partial\n","    # Calculate confusion matrix on test set data\n","    confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n","\n","    accuracy = metrics.accuracy_score(y_test,y_pred)\n","    kappa = metrics.cohen_kappa_score(y_test,y_pred)\n","    #F1\n","    f1_micro = metrics.f1_score(y_test,y_pred, average='micro')\n","    f1_macro = metrics.f1_score(y_test,y_pred, average='macro')\n","    f1_weighted = metrics.f1_score(y_test,y_pred, average='weighted')\n","\n","    #Precision\n","    precision_micro = metrics.precision_score(y_test,y_pred, average='micro')\n","    precision_macro = metrics.precision_score(y_test,y_pred, average='macro')\n","    precision_weighted = metrics.precision_score(y_test,y_pred, average='weighted')\n","\n","    #Recall\n","    recall_micro = metrics.recall_score(y_test,y_pred, average='micro')\n","    recall_macro = metrics.recall_score(y_test,y_pred, average='macro')\n","    recall_weighted = metrics.recall_score(y_test,y_pred, average='weighted')\n","\n","    test_metrics=[accuracy, kappa, f1_macro, f1_micro, f1_weighted, precision_macro, precision_micro, precision_weighted, recall_macro, recall_micro, recall_weighted]\n","    test_metrics"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7747747747747747,\n"," 0.6888315765866786,\n"," 0.6549341608265634,\n"," 0.7747747747747747,\n"," 0.7868988196033975,\n"," 0.6717171717171718,\n"," 0.7747747747747747,\n"," 0.8018928018928019,\n"," 0.6405529953917051,\n"," 0.7747747747747747,\n"," 0.7747747747747747]"]},"metadata":{"tags":[]},"execution_count":15}]}]}